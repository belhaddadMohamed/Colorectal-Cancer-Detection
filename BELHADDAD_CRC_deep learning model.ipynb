{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Data acquisition and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data acquisition and selection\n",
    "train_data_dir = './colon_image_sets/training_set'\n",
    "test_data_dir = './colon_image_sets/test_set'\n",
    "\n",
    "# Remove corrupted or invalid images\n",
    "def is_valid_image(img_path):\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def remove_corrupted_images(dir_path):\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for f in files:\n",
    "            img_path = os.path.join(root, f)\n",
    "            if not is_valid_image(img_path):\n",
    "                os.remove(img_path)\n",
    "\n",
    "remove_corrupted_images(train_data_dir)\n",
    "remove_corrupted_images(test_data_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning and preprocessing\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Methodology"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (feature extraction and selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Add a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Add the second convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "\n",
    "# Add another max pooling layer\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Flatten the layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a fully connected layer\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "# Add a dropout layer to prevent overfitting\n",
    "model.add(Dropout(rate = 0.5))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               1605760   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,625,281\n",
      "Trainable params: 1,625,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit_generator(\n",
    "    training_set,\n",
    "    steps_per_epoch=8000,\n",
    "    epochs=25,\n",
    "    validation_data=test_set,\n",
    "    validation_steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
